# 大模型简介

## 大模型的演变和概念

人工智能按照技术实现的不同可被划分为多个子领域，各个子领域之间往往相互关联和影响。主要包括：人工智能、机器学习、深度学习、生成式人工智能等。

### 机器学习

1. 监督学习：有标准。
2. 非监督学习：自己分组。
3. 强化学习：判断正确给奖励。

### 深度学习

深度学习算法试图模拟人类大脑的工作方式，其灵感来源于神经生物学，它通过对大量数据的学习，自动提取出数据的高层次特征和模式，从而实现图像识别、语音识别、自然语言处理（NLP）等任务。按照架构的不同，神经网络可以分为：**卷织神经网络（CNNs）**、**循环神经网络（RNNs）**、**Transformer网络**等等。

## 大模型的使用和训练

### 大模型的训练

大模型的训练整体上分为三个阶段：**预训练**、**SFT（监督微调）**以及**RLHF（基于人类反馈的强化学习）**。

## 大模型的特点与分类

### 大模型的特点

1. 规模和参数量大
2. 适应性和灵活性强
3. 广泛数据集的预训练
4. 计算资源需求大

### 大模型的分类

#### 大语言模型（LLM）

1. 编码器模型
- 训练目标：掩码语言建模（完形填空）
- 代表性的模型：**BERT**、**RoBERTa**、**ALBERT**
- 特点：双向上下文、语言理解好
- 缺点：使用`[mask]`特殊符号，导致预训练-微调差异；假设所有被**mask**的**token**互相独立
- 适用的场景：分类、回归等判别式任务

2. 解码器模型
- 训练目标：自回归语言建模（预测下一个）
- 代表行的模型：**GPT（OpenAI）**、**Llama（FaceBook）**、**PaLM（Google）**
- 特点：天然适合生成类任务，容易造成大规模的训练数据
- 缺点：局限于单向建模，难以同时利用双向上下文信息
- 适用的场景：开放生成类任务

3. 编解码器模型
- 训练目标：序列到序列建模（填充一段内容）
- 代表性的模型：**T5**、**BART**
- 适用的场景：兼具判别和生成能力，翻译任务

#### 多模态模型（VLM）
1. 计算机视觉模型
2. 音频处理模型

## 大模型的工作流程

## 大模型的应用




