# RAG


## 什么是RAG？

1. 目前大语言模型的三大问题：**偏见**、**幻觉**、**过时**。

2. 检索增强生成简单理解就是：`外部数据库+问题检索+LLM生成`。

![An image](/llm/llm-8.png)

3. 过程：**数据提取** -- **embedding（向量化）** -- **创建索引** -- **检索** -- **自动排序（Remark）** -- **LLM归纳生成**

4. 解决的问题：

- 长尾知识
- 私有数据
- 数据及时性
- 来源性和可解释性
- 幻觉（不能解决）

## RAG增强检索是如何工作的？

1. 工作流程：

- 知识库：大量的文本。
- 文本切分：切分成段落`chunks`。
- 将段落向量化`embedding`，存放到**向量数据库**中。
- 将用户的提问向量化`embedding`，在**向量数据库**中检索出最相似的段落`context`。
- 将段落`context`和用户的提问一起集成到`Prompt`中，输入给大模型`LLM`。
- 大模型`LLM`返回结果给用户

## 提示工程、RAG、微调

在用户提问大模型，得到回复错误的原因：

1. 没问清楚
- 解决方法：提示工程。（改善提问方式）
2. 缺乏相关知识
- 解决方法：RAG。（丰富知识）
3. 能力不足
- 解决方法：微调。（提高大模型的能力）






